---
title: 하둡이란?
categories: [Hadoop]
tags: [hadoop, bigdata]
---

### 하둡이란?  
> 2006년 야후의 더그 커팅이 '넛치'라는 검색엔진을 개발하는 과정에서 대용량의 비정형 데이터를 기존의 RDB 기술로는 처리가 힘들다는 것을 깨닫고, 새로운 기술을 찾는 중 구글에서 발표한 GFS와 MapReduce 관련 논문을 참고하여 개발하고, 이후 아파치 재단에서 오픈 소스로 공개된 기술이다.  
하둡은 하나의 좋은 컴퓨터를 이용하여 데이터를 처리하는 대신, 적당한 성능의 범용 컴퓨터 여러대를 클러스터화 하여 데이터를 처리하는 것을 목표로 한다.
<br/>  
즉, 하둡은 큰 크기의 데이터를 여러대의 컴퓨터에서 병렬로 동시에 처리하여 처리 속도를 높이는 것을 목적으로 하는 분산처리 오픈소스 프레임워크라고 할 수 있다.

### 하둡의 구성요소
> 하둡은 4개의 주요 모듈로 구성된다.

* Hadoop Common
    * 하둡의 다른 모듈을 지원하기 위한 공통 컴포넌트 모듈
   
* Hadoop HDFS
    * 분산저장을 처리하기 위한 모듈
    * 여러개의 서버를 하나의 서버처럼 묶어서 데이터를 저장

* Hadoop YARN
    * 병렬처리를 위한 클러스터 자원관리 및 스케줄링 담당

* Hadoop MapReduce
    * 분산되어 저장된 데이터를 병렬 처리할 수 있게 해주는 분산 처리 모듈
  
###### 각 모듈의 좀 더 자세한 사항은 추후 블로그에 업데이트 될 예정입니다.

### 하둡의 장단점  

* 장점
    * 오픈소스이기 때문에 라이센스에 대한 비용 부담이 적음
    * 시스템을 중단하지 않고, 장비의 추가가 용이 (Scale Out)
    * 일부 장비에 장애가 발생하더라도 전체 시스템 사용성에 영향이 적음(Faulttolerance)
    * 저렴한 구축 비용과 비용 대비 빠른 데이터 처리
    * 오프라인 배치 프로세싱에 최적화

* 단점
    * HDFS에 저장된 데이터를 변경 불가
    * 실시간 데이터 분석 같이 신속하게 처리해야 하는 작업에는 부적합(최근 사용해본 결과 Join 등의 연산이 굉장히 느림!)
    * 너무 많은 버전과 부실한 서포트
    * 설정의 어려움

##### Reference  
[https://wikidocs.net/31519](https://wikidocs.net/31519)